# -*- coding: utf-8 -*-
"""
Vibereader LINE Webhook Bot (YouTube -> Transcript -> OpenAI Summary)

âœ… Features
- LINE webhook endpoint: POST /webhook
- Extract YouTube URL, fetch transcript, do Map-Reduce summarization (better quality for ~60min videos)
- Reply immediately ("é–‹å§‹è™•ç†") then push final summary
- Background thread to avoid LINE webhook timeout
- Usage logging to usage_log.jsonl (per OpenAI call)
- Error logging to error_log.txt

ğŸ”§ Required .env (or environment variables)
- LINE_CHANNEL_ACCESS_TOKEN
- OPENAI_API_KEY

(Optional but recommended)
- LINE_CHANNEL_SECRET   # if set, will verify X-Line-Signature
"""

import os
import re
import json
import time
import hmac
import base64
import hashlib
import traceback
import threading
from datetime import datetime

import requests
from flask import Flask, request, abort
from dotenv import load_dotenv
from youtube_transcript_api import YouTubeTranscriptApi
from openai import OpenAI
from typing import Optional


# -----------------------------
# Load env
# -----------------------------
load_dotenv()

LINE_TOKEN = (os.getenv("LINE_CHANNEL_ACCESS_TOKEN") or "").strip()
LINE_CHANNEL_SECRET = (os.getenv("LINE_CHANNEL_SECRET") or "").strip()  # optional but recommended
OPENAI_API_KEY = (os.getenv("OPENAI_API_KEY") or "").strip()

if not LINE_TOKEN:
    raise RuntimeError("ç¼ºå°‘ LINE_CHANNEL_ACCESS_TOKENï¼Œè«‹åœ¨ .env è¨­å®š")
if not OPENAI_API_KEY:
    raise RuntimeError("ç¼ºå°‘ OPENAI_API_KEYï¼Œè«‹åœ¨ .env è¨­å®š")

client = OpenAI(api_key=OPENAI_API_KEY)

# Model
OPENAI_MODEL = "gpt-4o-mini"

# Summary template (macro economist, zh-TW)
SUMMARY_TEMPLATE = """
ä½ æ˜¯ä¸€ä½è³‡æ·±ç¸½é«”ç¶“æ¿Ÿåˆ†æå¸«ã€‚è«‹æ ¹æ“šæä¾›çš„å­—å¹•å…§å®¹ï¼Œç”¨ç¹é«”ä¸­æ–‡ç”¢å‡ºã€Œ10 åˆ†é˜å…§è®€å®Œã€çš„å½±ç‰‡æ‘˜è¦ã€‚
è¦å‰‡ï¼š
- åš´ç¦æœæ’…ã€‚è‹¥å­—å¹•æœªæ˜ç¢ºæåˆ°ï¼Œè«‹å¯«ã€Œï¼ˆåŸæ–‡æœªæä¾›ç´°ç¯€ï¼‰ã€ã€‚
- æ‰€æœ‰æ•¸å­—ã€æ™‚é–“ã€ç™¾åˆ†æ¯”ã€æ”¿ç­–æ¢ä»¶ï¼Œå‹™å¿…ä¿ç•™ä¸¦æ”¾åœ¨ã€é—œéµæ•¸å­—èˆ‡å‡è¨­ã€‘ä¸­ã€‚
- åœ¨ã€å¸‚å ´å«ç¾©ã€‘ä¸­ç”¨ã€Œå› ç‚ºâ€¦æ‰€ä»¥â€¦ã€æè¿°å› æœéˆï¼Œä¸è¦åªä¸‹çµè«–ã€‚
- å…§å®¹ä»¥ã€Œç¸½ç¶“/åˆ©ç‡/é€šè†¨/å°±æ¥­/ç¾å…ƒ/é¢¨éšªè³‡ç”¢ã€è¦–è§’ç‚ºä¸»ã€‚

è¼¸å‡ºæ ¼å¼ï¼ˆè«‹åš´æ ¼ç…§é †åºï¼‰ï¼š
ã€ä¸‰è¡Œç¸½çµã€‘
- ...
- ...
- ...

ã€é‡é»æ¢åˆ—ã€‘
- ...ï¼ˆ8â€“12 é»ï¼Œæ¯é»æœ€å¤š 2 è¡Œï¼‰

ã€é—œéµæ•¸å­—èˆ‡å‡è¨­ã€‘
- æŒ‡æ¨™/æ•¸å­—ï¼š...ï¼ˆæ¢ä»¶ï¼š... / æ™‚é»ï¼š...ï¼‰

ã€å¸‚å ´å«ç¾©ã€‘
- è‚¡å¸‚ï¼š...
- å‚µå¸‚ï¼š...
- åŒ¯ç‡ï¼š...

ã€é¢¨éšªèˆ‡è¿½è¹¤æ¸…å–®ã€‘
- ...ï¼ˆ3â€“6 é»ï¼‰
""".strip()

MAP_INSTRUCTIONS = """
ä½ æ˜¯ç¸½é«”ç¶“æ¿Ÿåˆ†æå¸«åŠ©ç†ã€‚è«‹æŠŠé€™ä¸€æ®µå­—å¹•æç…‰æˆã€Œæ®µè½é‡é»ã€ï¼Œè¦æ±‚ï¼š
- åš´ç¦æœæ’…ï¼›ä¸ç¢ºå®šå°±å¯«ï¼ˆåŸæ–‡æœªæä¾›ç´°ç¯€ï¼‰
- åªä¿ç•™é€™æ®µå…§çœŸæ­£å‡ºç¾çš„è«–é»èˆ‡æ•¸å­—
- ä»¥æ¢åˆ—è¼¸å‡º 5â€“8 é»ï¼Œæ¯é»ä¸€å¥è©±ï¼Œç›¡é‡ä¿ç•™æ•¸å­—/æ¢ä»¶/æ™‚é–“
è¼¸å‡ºåªè¦æ¢åˆ—ï¼Œä¸è¦åŠ å…¶ä»–æ¨™é¡Œã€‚
""".strip()


# -----------------------------
# Flask app
# -----------------------------
app = Flask(__name__)


# -----------------------------
# Helpers: OpenAI calls + usage logging
# -----------------------------
def make_json_safe(obj):
    """æŠŠä»»ä½•ç‰©ä»¶è½‰æˆå¯è¢« json.dumps çš„çµæ§‹ï¼ˆdict/list/str/int/...ï¼‰"""
    if obj is None:
        return None
    if isinstance(obj, (str, int, float, bool)):
        return obj
    if isinstance(obj, dict):
        return {k: make_json_safe(v) for k, v in obj.items()}
    if isinstance(obj, (list, tuple, set)):
        return [make_json_safe(x) for x in obj]
    # æœ‰äº› SDK ç‰©ä»¶æœ‰ __dict__
    if hasattr(obj, "__dict__"):
        return make_json_safe(obj.__dict__)
    # æœ€å¾Œå…œåº•ï¼šè½‰å­—ä¸²
    return str(obj)

def openai_call(instructions: str, input_text: str) -> tuple[str, dict]:
    """Call OpenAI once. Return (output_text, usage_dict)."""
    resp = client.responses.create(
        model=OPENAI_MODEL,
        instructions=instructions,
        input=input_text,
    )

    text = (getattr(resp, "output_text", "") or "").strip()

    usage = getattr(resp, "usage", None)
    if usage is None:
        usage_dict = {}
    elif isinstance(usage, dict):
        usage_dict = usage
    else:
        usage_dict = usage.__dict__ if hasattr(usage, "__dict__") else {"usage": str(usage)}

    return text, usage_dict


def log_usage(tag: str, usage: dict, extra: dict = None) -> None:
    """æŠŠæ¯æ¬¡ token ä½¿ç”¨é‡å¯«åˆ° usage_log.jsonlï¼ˆå®¹éŒ¯ï¼šå¯åºåˆ—åŒ–è½‰æ›ï¼‰"""
    rec = {
        "ts": datetime.now().isoformat(timespec="seconds"),
        "tag": tag,
        "model": OPENAI_MODEL,
        "usage": make_json_safe(usage),
    }
    if extra:
        rec["extra"] = make_json_safe(extra)

    with open("usage_log.jsonl", "a", encoding="utf-8") as f:
        f.write(json.dumps(rec, ensure_ascii=False) + "\n")



# -----------------------------
# LINE signature verification (optional)
# -----------------------------
def verify_line_signature(raw_body: bytes, signature_b64: str) -> bool:
    """
    Verify X-Line-Signature if LINE_CHANNEL_SECRET is set.
    LINE signature = base64(hmac_sha256(channel_secret, body))
    """
    if not LINE_CHANNEL_SECRET:
        return True  # skip verification if secret not provided

    mac = hmac.new(LINE_CHANNEL_SECRET.encode("utf-8"), raw_body, hashlib.sha256).digest()
    expected = base64.b64encode(mac).decode("utf-8")
    return hmac.compare_digest(expected, signature_b64 or "")


# -----------------------------
# YouTube transcript helpers
# -----------------------------
def extract_video_id(url: str) -> str:
    """Extract YouTube videoId (11 chars)."""
    m = re.search(r"(v=|youtu\.be/)([A-Za-z0-9_\-]{11})", url)
    if not m:
        raise ValueError("é€™ä¸æ˜¯æœ‰æ•ˆçš„ YouTube å½±ç‰‡é€£çµï¼Œè«‹è²¼å®Œæ•´ç¶²å€")
    return m.group(2)


def fetch_cc_transcript_text(video_id: str) -> str:
    """
    Fetch transcript. Prefer Chinese (Traditional) then fallback.
    """
    api = YouTubeTranscriptApi()
    data = api.fetch(video_id, languages=["zh-Hant", "zh-TW", "zh", "en"])
    # youtube_transcript_api may return objects; keep safe access
    lines = []
    for item in data:
        t = getattr(item, "text", None)
        if t is None and isinstance(item, dict):
            t = item.get("text")
        if t:
            lines.append(t)
    return "\n".join(lines)


def compress_transcript(text: str, max_chars: int = 200000) -> str:
    """
    Light cleanup:
    - strip empty lines
    - remove exact duplicates
    - keep up to max_chars (very large; mainly to avoid insane memory)
    """
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    seen = set()
    uniq = []
    for ln in lines:
        if ln not in seen:
            seen.add(ln)
            uniq.append(ln)
    joined = "\n".join(uniq)
    return joined[:max_chars]


def chunk_text_by_chars(text: str, chunk_size: int = 4500, overlap: int = 350) -> list[str]:
    """
    Chunk by characters, with overlap to avoid cutting important context.
    Suitable for subtitle text.
    """
    text = text.strip()
    if not text:
        return []
    chunks = []
    i = 0
    n = len(text)
    while i < n:
        j = min(n, i + chunk_size)
        chunks.append(text[i:j])
        if j == n:
            break
        i = max(0, j - overlap)
    return chunks


def openai_map_reduce_summary(transcript_text: str, youtube_url: str) -> str:
    """
    Map-Reduce summary:
    1) Map: summarize each chunk (5-8 bullets)
    2) Reduce: merge chunk summaries into final structured report
    """
    cleaned = compress_transcript(transcript_text, max_chars=200000)
    chunks = chunk_text_by_chars(cleaned, chunk_size=4500, overlap=350)

    if not chunks:
        return "æŠ“ä¸åˆ°å­—å¹•å…§å®¹ï¼ˆå¯èƒ½å½±ç‰‡æœªæä¾›å­—å¹•æˆ–å­—å¹•å–å¾—å¤±æ•—ï¼‰ã€‚"

    partials: list[str] = []
    for idx, ch in enumerate(chunks, start=1):
        input_text = (
            f"ä¾†æºå½±ç‰‡ï¼š{youtube_url}\n"
            f"é€™æ˜¯å­—å¹•ç¬¬ {idx}/{len(chunks)} æ®µã€‚\n\n"
            f"{ch}"
        )
        part, usage = openai_call(MAP_INSTRUCTIONS, input_text)
        log_usage(f"map_{idx}", usage, extra={"chunks": len(chunks)})
        if part:
            partials.append(f"ã€æ®µè½ {idx}ã€‘\n{part}")

        # Small pause to reduce rate-limit spikes (optional)
        time.sleep(0.15)

    if not partials:
        return "å­—å¹•æ‘˜è¦å¤±æ•—ï¼ˆæœªå–å¾—ä»»ä½•æ®µè½æ‘˜è¦ï¼‰ã€‚"

    reduce_input = "\n\n".join(partials)
    final_input = (
        f"ä¾†æºå½±ç‰‡ï¼š{youtube_url}\n"
        "ä»¥ä¸‹æ˜¯å„æ®µå­—å¹•çš„æ®µè½é‡é»ï¼ˆå·²åˆ†æ®µæ•´ç†ï¼‰ã€‚\n"
        "è«‹ä¾ç…§æ¨¡æ¿ç”¢å‡ºæœ€çµ‚æ‘˜è¦ã€‚\n\n"
        f"{reduce_input}"
    )

    final_text, usage = openai_call(SUMMARY_TEMPLATE, final_input)
    log_usage("reduce_final", usage, extra={"chunks": len(chunks)})

    return final_text.strip() or "æ‘˜è¦ç”¢ç”Ÿå¤±æ•—ï¼ˆæ¨¡å‹æœªè¼¸å‡ºå…§å®¹ï¼‰ã€‚"


# -----------------------------
# LINE Messaging API helpers
# -----------------------------
def line_reply(reply_token: str, text: str) -> None:
    """Reply to user via Reply API (token usable only once)."""
    url = "https://api.line.me/v2/bot/message/reply"
    headers = {
        "Authorization": f"Bearer {LINE_TOKEN}",
        "Content-Type": "application/json; charset=utf-8",
    }
    payload = {
        "replyToken": reply_token,
        "messages": [{"type": "text", "text": text[:4900]}],
    }
    data = json.dumps(payload, ensure_ascii=False).encode("utf-8")
    r = requests.post(url, headers=headers, data=data, timeout=30)
    r.raise_for_status()


def line_push(user_id: str, text: str) -> None:
    """Push message to user via Push API."""
    url = "https://api.line.me/v2/bot/message/push"
    headers = {
        "Authorization": f"Bearer {LINE_TOKEN}",
        "Content-Type": "application/json; charset=utf-8",
    }
    payload = {"to": user_id, "messages": [{"type": "text", "text": text[:4900]}]}
    data = json.dumps(payload, ensure_ascii=False).encode("utf-8")
    r = requests.post(url, headers=headers, data=data, timeout=60)
    r.raise_for_status()


# -----------------------------
# Background processing
# -----------------------------
def process_event(event: dict) -> None:
    """
    Heavy work in background:
    - Extract URL
    - Fetch transcript
    - Map-Reduce summarize
    - Push result
    """
    try:
        reply_token = event.get("replyToken", "")
        source = event.get("source", {}) or {}
        user_id = source.get("userId", "")

        msg = event.get("message", {}) or {}
        user_text = (msg.get("text") or "").strip()

        m = re.search(r"(https?://\S+)", user_text)
        if not m:
            if reply_token:
                line_reply(reply_token, "è«‹è²¼ä¸Š YouTube å½±ç‰‡é€£çµï¼Œæˆ‘æœƒå¹«ä½ æ‘˜è¦ã€‚")
            return

        youtube_url = m.group(1)

        # Reply quickly (reply token can be used only once)
        if reply_token:
            line_reply(reply_token, "æ”¶åˆ°é€£çµï¼Œæ­£åœ¨æŠ“å­—å¹•ä¸¦æ•´ç†æ‘˜è¦ï¼ˆç´„ 1â€“3 åˆ†é˜ï¼Œè¦–å½±ç‰‡é•·åº¦èˆ‡å­—å¹•è€Œå®šï¼‰")

        # Heavy steps
        video_id = extract_video_id(youtube_url)
        transcript = fetch_cc_transcript_text(video_id)
        summary = openai_map_reduce_summary(transcript, youtube_url)

        # Push final summary
        if user_id:
            line_push(user_id, summary)
        else:
            # fallback: cannot push, no userId
            # (rare, but keep safe)
            pass

    except Exception:
        err = traceback.format_exc()
        with open("error_log.txt", "w", encoding="utf-8") as f:
            f.write(err)
        # Try push an error message if possible
        try:
            user_id = (event.get("source", {}) or {}).get("userId", "")
            if user_id:
                line_push(user_id, "æŠ±æ­‰ï¼Œè™•ç†æ‘˜è¦æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚æˆ‘å·²è¨˜éŒ„éŒ¯èª¤è¨Šæ¯ï¼ˆerror_log.txtï¼‰ã€‚")
        except Exception:
            pass


# -----------------------------
# Webhook
# -----------------------------
@app.route("/webhook", methods=["POST"])
def webhook():
    # Verify signature (optional)
    raw_body = request.get_data()  # bytes
    signature = request.headers.get("X-Line-Signature", "")

    if not verify_line_signature(raw_body, signature):
        abort(400)

    body = request.get_json(silent=True)
    if not body:
        abort(400)

    try:
        events = body.get("events", []) or []

        for event in events:
            if event.get("type") != "message":
                continue
            msg = event.get("message", {}) or {}
            if msg.get("type") != "text":
                continue

            # Run in background thread so webhook returns immediately (LINE verify stable)
            threading.Thread(target=process_event, args=(event,), daemon=True).start()

        return "OK", 200

    except Exception:
        err = traceback.format_exc()
        with open("error_log.txt", "w", encoding="utf-8") as f:
            f.write(err)
        return "ERROR", 500


# -----------------------------
# Run locally
# -----------------------------
if __name__ == "__main__":
    # Local dev server
    app.run(host="0.0.0.0", port=8000, debug=True)
